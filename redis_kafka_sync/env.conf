# Source Redis Configuration (Local instance where data originates)
SOURCE_REDIS_HOST=redis-cache
SOURCE_REDIS_PORT=6379
SOURCE_REDIS_PASSWORD=
SOURCE_REDIS_DB_SEARCH_RANGE="0-15" # For stream discovery
SOURCE_REDIS_ENCODING=utf-8 # Default encoding for string fields

# Target Redis Configuration (Remote instance for caching before Kafka)
TARGET_REDIS_HOST=remote-redis-url
TARGET_REDIS_PORT=6379
TARGET_REDIS_PASSWORD=
TARGET_REDIS_DB=0 # Default DB for caching messages before Kafka send
TARGET_REDIS_MAXMEMORY=1gb
TARGET_REDIS_MAXMEMORY_POLICY=volatile-ttl
TARGET_REDIS_TIME_TO_LIVE=3600 # TTL for cached messages (before Kafka sync)
TARGET_REDIS_SYNC_TTL=604800 # TTL for sync markers (after Kafka sync), e.g., 7 days
TARGET_REDIS_POOL_SIZE=10

# PostgreSQL Configuration
POSTGRES_HOST=postgres
POSTGRES_PORT=5432
POSTGRES_DB=edn
POSTGRES_USER=postgres
POSTGRES_PASSWORD=postgres
POSTGRES_SCHEMA=public

# Sync Parameters
SYNC_INTERVAL=5  # Redis to PostgreSQL sync interval in seconds

# Redis Stream Configuration
REDIS_STREAMS_ENABLED=true
REDIS_STREAMS=biosignal-stream
REDIS_CONSUMER_GROUP=producer-group
REDIS_CONSUMER_NAME=producer-1
STREAM_BATCH_SIZE=100
POLL_INTERVAL=0.1
MONITOR_INTERVAL=5 

# Stream Auto-Discovery Configuration
STREAM_AUTO_DISCOVERY=false # Set to true to enable
STREAM_DISCOVERY_PATTERNS=*-stream,device:*:stream,biosignal-*
STREAM_DISCOVERY_INTERVAL=10
STREAM_TARGET_TOPIC_MAP='{"device:*:stream": "device-data-topic", "*-stream": "default-stream-topic"}' # Maps stream patterns to Kafka topics

# Redis DB Search Range - Comma-separated list of DB numbers or ranges to search
# Examples: "0,1,2" (only DBs 0,1,2), "0-3,5,7-9" (DBs 0,1,2,3,5,7,8,9)
REDIS_DB_SEARCH_RANGE=0-15  # Default: all Redis databases (0-15) 

# Kafka Configuration (Target Destination)
KAFKA_BOOTSTRAP_SERVERS=remote-kafka:9092
KAFKA_TOPIC=default-sync-topic # Default topic if not specified per message/stream
KAFKA_SCHEMA_REGISTRY_URL=http://remote-schema-registry:8081
KAFKA_SECURITY_PROTOCOL=PLAINTEXT
KAFKA_MAX_REQUEST_SIZE=20971520
KAFKA_MAX_CONCURRENT_SENDS=100 # Handled within KafkaManager
PRODUCER_CLIENT_ID=redis-kafka-sync.default

# Kafka Security (Only used if KAFKA_IS_SWARM_MODE=false and protocol requires it)
KAFKA_IS_SWARM_MODE=false # Set to true to simplify security in Swarm (often PLAINTEXT)
KAFKA_SASL_MECHANISM=PLAIN
KAFKA_SASL_USERNAME=producer-user
KAFKA_SASL_PASSWORD=producer-secret
KAFKA_SSL_TRUSTSTORE_LOCATION=/etc/kafka/secrets/kafka.client.truststore.jks
KAFKA_SSL_TRUSTSTORE_PASSWORD=changeit
KAFKA_SSL_PEM_LOCATION=/etc/kafka/secrets/kafka.client.truststore.pem # Preferred if available

# Logging Configuration
LOG_LEVEL=INFO # e.g., DEBUG, INFO, WARNING, ERROR
LOG_FILE=redis_kafka_sync.log # Optional: Log to file 